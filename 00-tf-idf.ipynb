{"cells":[{"metadata":{},"cell_type":"markdown","source":"## TF-IDF 알고리즘"},{"metadata":{"trusted":true},"cell_type":"code","source":"docs = [\n  '먹고 싶은 사과', # 문서0 \n  '먹고 싶은 바나나', # 문서1\n  '길고 노란 바나나 바나나', # 문서2 \n  '저는 과일이 좋아요' # 문서3 \n]","execution_count":1,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.feature_extraction.text import CountVectorizer # CountVectorizer : tf-idf 중 tf 까지의 과정만 거침\nvect = CountVectorizer() # Counter Vectorizer 객체 생성 ","execution_count":2,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 문장을 Counter Vectorizer 형태로 변형 \ncountvect = vect.fit_transform(docs) \ncountvect # 4x9 : 4개의 문서에 9개의 단어 => (4x9)형태를 가지는 \"sparse matrix\" 가 생성됨","execution_count":4,"outputs":[{"output_type":"execute_result","execution_count":4,"data":{"text/plain":"<4x9 sparse matrix of type '<class 'numpy.int64'>'\n\twith 12 stored elements in Compressed Sparse Row format>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# toarray()를 통해서 문장이 Vector 형태의 값을 얻을 수 있음 \n# 하지만, 각 인덱스와 컬럼이 무엇을 의미하는지에 대해서는 알 수가 없음 \ncountvect.toarray()","execution_count":5,"outputs":[{"output_type":"execute_result","execution_count":5,"data":{"text/plain":"array([[0, 0, 0, 1, 0, 1, 1, 0, 0],\n       [0, 0, 0, 1, 1, 0, 1, 0, 0],\n       [0, 1, 1, 0, 2, 0, 0, 0, 0],\n       [1, 0, 0, 0, 0, 0, 0, 1, 1]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"vect.vocabulary_ # vocabulary_ 함수","execution_count":6,"outputs":[{"output_type":"execute_result","execution_count":6,"data":{"text/plain":"{'먹고': 3,\n '싶은': 6,\n '사과': 5,\n '바나나': 4,\n '길고': 1,\n '노란': 2,\n '저는': 7,\n '과일이': 0,\n '좋아요': 8}"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"sorted(vect.vocabulary_)","execution_count":7,"outputs":[{"output_type":"execute_result","execution_count":7,"data":{"text/plain":"['과일이', '길고', '노란', '먹고', '바나나', '사과', '싶은', '저는', '좋아요']"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"import pandas as pd\ncountvect_df = pd.DataFrame(countvect.toarray(), columns = sorted(vect.vocabulary_))\ncountvect_df.index = ['문서1', '문서2', '문서3', '문서4']\ncountvect_df","execution_count":8,"outputs":[{"output_type":"execute_result","execution_count":8,"data":{"text/plain":"     과일이  길고  노란  먹고  바나나  사과  싶은  저는  좋아요\n문서1    0   0   0   1    0   1   1   0    0\n문서2    0   0   0   1    1   0   1   0    0\n문서3    0   1   1   0    2   0   0   0    0\n문서4    1   0   0   0    0   0   0   1    1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>과일이</th>\n      <th>길고</th>\n      <th>노란</th>\n      <th>먹고</th>\n      <th>바나나</th>\n      <th>사과</th>\n      <th>싶은</th>\n      <th>저는</th>\n      <th>좋아요</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>문서1</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>문서2</th>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>문서3</th>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n      <td>0</td>\n      <td>2</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>문서4</th>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 위의 Data Frame 형태의 유사도를 계산 \nfrom sklearn.metrics.pairwise import cosine_similarity\ncosine_similarity(countvect_df, countvect_df)","execution_count":9,"outputs":[{"output_type":"execute_result","execution_count":9,"data":{"text/plain":"array([[1.        , 0.66666667, 0.        , 0.        ],\n       [0.66666667, 1.        , 0.47140452, 0.        ],\n       [0.        , 0.47140452, 1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ]])"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"0번문서는 1번과 유사하다는 결론을 얻을 수 있음. 동일한 방식으로 TF-IDF를 수행하면 아래와 같음 "},{"metadata":{"trusted":true},"cell_type":"code","source":"# TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer()\ntfvect = vect.fit(docs) # fit() -> 변환","execution_count":10,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidv_df = pd.DataFrame(tfvect.transform(docs).toarray(), columns = sorted(vect.vocabulary_))\ntfidv_df.index = ['문서1', '문서2', '문서3', '문서4']\ntfidv_df","execution_count":11,"outputs":[{"output_type":"execute_result","execution_count":11,"data":{"text/plain":"         과일이       길고       노란        먹고      바나나        사과        싶은  \\\n문서1  0.00000  0.00000  0.00000  0.526405  0.00000  0.667679  0.526405   \n문서2  0.00000  0.00000  0.00000  0.577350  0.57735  0.000000  0.577350   \n문서3  0.00000  0.47212  0.47212  0.000000  0.74445  0.000000  0.000000   \n문서4  0.57735  0.00000  0.00000  0.000000  0.00000  0.000000  0.000000   \n\n          저는      좋아요  \n문서1  0.00000  0.00000  \n문서2  0.00000  0.00000  \n문서3  0.00000  0.00000  \n문서4  0.57735  0.57735  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>과일이</th>\n      <th>길고</th>\n      <th>노란</th>\n      <th>먹고</th>\n      <th>바나나</th>\n      <th>사과</th>\n      <th>싶은</th>\n      <th>저는</th>\n      <th>좋아요</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>문서1</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.526405</td>\n      <td>0.00000</td>\n      <td>0.667679</td>\n      <td>0.526405</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>문서2</th>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.577350</td>\n      <td>0.57735</td>\n      <td>0.000000</td>\n      <td>0.577350</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>문서3</th>\n      <td>0.00000</td>\n      <td>0.47212</td>\n      <td>0.47212</td>\n      <td>0.000000</td>\n      <td>0.74445</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n    </tr>\n    <tr>\n      <th>문서4</th>\n      <td>0.57735</td>\n      <td>0.00000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.57735</td>\n      <td>0.57735</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"from sklearn.metrics.pairwise import cosine_similarity\ncosine_similarity(tfidv_df, tfidv_df)","execution_count":12,"outputs":[{"output_type":"execute_result","execution_count":12,"data":{"text/plain":"array([[1.        , 0.60784064, 0.        , 0.        ],\n       [0.60784064, 1.        , 0.42980824, 0.        ],\n       [0.        , 0.42980824, 1.        , 0.        ],\n       [0.        , 0.        , 0.        , 1.        ]])"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nvect = TfidfVectorizer(max_features=4)\ntfvect = vect.fit(docs)","execution_count":13,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tfidv_df = pd.DataFrame(tfvect.transform(docs).toarray(), columns = sorted(vect.vocabulary_))\ntfidv_df.index = ['문서1', '문서2', '문서3', '문서4']\ntfidv_df","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"     과일이        먹고      바나나        싶은\n문서1  0.0  0.707107  0.00000  0.707107\n문서2  0.0  0.577350  0.57735  0.577350\n문서3  0.0  0.000000  1.00000  0.000000\n문서4  1.0  0.000000  0.00000  0.000000","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>과일이</th>\n      <th>먹고</th>\n      <th>바나나</th>\n      <th>싶은</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>문서1</th>\n      <td>0.0</td>\n      <td>0.707107</td>\n      <td>0.00000</td>\n      <td>0.707107</td>\n    </tr>\n    <tr>\n      <th>문서2</th>\n      <td>0.0</td>\n      <td>0.577350</td>\n      <td>0.57735</td>\n      <td>0.577350</td>\n    </tr>\n    <tr>\n      <th>문서3</th>\n      <td>0.0</td>\n      <td>0.000000</td>\n      <td>1.00000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>문서4</th>\n      <td>1.0</td>\n      <td>0.000000</td>\n      <td>0.00000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# 단점 : 대규모 말뭉치를 다룰 때 메모리 사용량이 너무 많음 (높은 차원 가짐 & 매우 sparse한 형태의 데이터)\n# =>> \"word2vec\" 등장","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}